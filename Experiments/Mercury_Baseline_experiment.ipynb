{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f24b7620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishw\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "c:\\users\\vishw\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "--------------------\n",
      "Train Loss: 4.1929, Train Accuracy: 0.0493\n",
      "Epoch 1 duration: 213.2735 seconds\n",
      "Val Loss: 4.0508, Val Accuracy: 0.0664\n",
      "Epoch 2/10\n",
      "--------------------\n",
      "Train Loss: 3.9087, Train Accuracy: 0.0874\n",
      "Epoch 2 duration: 211.8815 seconds\n",
      "Val Loss: 3.8032, Val Accuracy: 0.1174\n",
      "Epoch 3/10\n",
      "--------------------\n",
      "Train Loss: 3.7208, Train Accuracy: 0.1207\n",
      "Epoch 3 duration: 212.3744 seconds\n",
      "Val Loss: 3.7822, Val Accuracy: 0.1154\n",
      "Epoch 4/10\n",
      "--------------------\n",
      "Train Loss: 3.5542, Train Accuracy: 0.1506\n",
      "Epoch 4 duration: 204.1191 seconds\n",
      "Val Loss: 3.6045, Val Accuracy: 0.1529\n",
      "Epoch 5/10\n",
      "--------------------\n",
      "Train Loss: 3.3952, Train Accuracy: 0.1816\n",
      "Epoch 5 duration: 204.3645 seconds\n",
      "Val Loss: 3.3791, Val Accuracy: 0.2009\n",
      "Epoch 6/10\n",
      "--------------------\n",
      "Train Loss: 3.2550, Train Accuracy: 0.2087\n",
      "Epoch 6 duration: 202.4921 seconds\n",
      "Val Loss: 3.2903, Val Accuracy: 0.2195\n",
      "Epoch 7/10\n",
      "--------------------\n",
      "Train Loss: 3.1196, Train Accuracy: 0.2344\n",
      "Epoch 7 duration: 201.2007 seconds\n",
      "Val Loss: 3.0919, Val Accuracy: 0.2516\n",
      "Epoch 8/10\n",
      "--------------------\n",
      "Train Loss: 2.8165, Train Accuracy: 0.2957\n",
      "Epoch 8 duration: 205.9482 seconds\n",
      "Val Loss: 2.8650, Val Accuracy: 0.2953\n",
      "Epoch 9/10\n",
      "--------------------\n",
      "Train Loss: 2.7342, Train Accuracy: 0.3144\n",
      "Epoch 9 duration: 202.2039 seconds\n",
      "Val Loss: 2.7646, Val Accuracy: 0.3156\n",
      "Epoch 10/10\n",
      "--------------------\n",
      "Train Loss: 2.6737, Train Accuracy: 0.3253\n",
      "Epoch 10 duration: 201.4836 seconds\n",
      "Val Loss: 2.7194, Val Accuracy: 0.3235\n",
      "Total training time: 2276.2530 seconds\n",
      "Total Computations (FLOPs approximation): 2.63e+15\n",
      "Estimated Total Clock Cycles: 5.24e+12 cycles\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Step 1: Download TinyImageNet dataset (subset of ImageNet)\n",
    "url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "data_dir = './data/tiny-imagenet-200'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"Downloading TinyImageNet dataset...\")\n",
    "    urllib.request.urlretrieve(url, './tiny-imagenet-200.zip')\n",
    "\n",
    "    # Extracting the dataset\n",
    "    with zipfile.ZipFile('./tiny-imagenet-200.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./data')\n",
    "    print(\"Dataset downloaded and extracted.\")\n",
    "\n",
    "# Step 2: Define data transformations\n",
    "input_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Step 3: Load datasets\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "# TinyImageNet has no explicit train/val split; let's create one\n",
    "full_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "\n",
    "# Use only the first 80 classes for your use case\n",
    "class_subset = 80\n",
    "targets = torch.tensor([sample[1] for sample in full_dataset.samples])\n",
    "indices = [i for i in range(len(targets)) if targets[i] < class_subset]\n",
    "\n",
    "# Create subset dataset\n",
    "subset_dataset = torch.utils.data.Subset(full_dataset, indices)\n",
    "\n",
    "# Split the subset into training and validation (80% train, 20% val)\n",
    "train_size = int(0.8 * len(subset_dataset))\n",
    "val_size = len(subset_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(subset_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Step 4: Define ResNet-50 model\n",
    "model = models.resnet50(pretrained=False)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, class_subset)  # Modify for 80 classes\n",
    "model = model.to(device)\n",
    "\n",
    "# Step 5: Define loss function, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Step 6: Training with computation counter\n",
    "def train_model_with_counter(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    total_start_time = time.time()\n",
    "    total_computations = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Compute FLOPs and update counter\n",
    "            total_computations += inputs.size(0) * inputs.size(2) * inputs.size(3) * num_features * class_subset\n",
    "\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f'Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.4f}')\n",
    "        print(f'Epoch {epoch + 1} duration: {epoch_duration:.4f} seconds')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_epoch_loss = val_loss / len(val_loader.dataset)\n",
    "        val_epoch_acc = val_correct / val_total\n",
    "        print(f'Val Loss: {val_epoch_loss:.4f}, Val Accuracy: {val_epoch_acc:.4f}')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    total_duration = time.time() - total_start_time\n",
    "    print(f'Total training time: {total_duration:.4f} seconds')\n",
    "    print(f'Total Computations (FLOPs approximation): {total_computations:.2e}')\n",
    "    return total_duration, total_computations\n",
    "\n",
    "# Start training and measure time\n",
    "total_training_time, total_computations = train_model_with_counter(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10)\n",
    "\n",
    "# Assuming the CPU clock speed of Google Colab is ~2.3 GHz (check your instance using `!lscpu`)\n",
    "cpu_clock_speed_ghz = 2.3\n",
    "total_clock_cycles = total_training_time * cpu_clock_speed_ghz * 1e9\n",
    "print(f\"Estimated Total Clock Cycles: {total_clock_cycles:.2e} cycles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3199b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/3\n",
      "--------------------\n",
      "Train Loss: 4.1769, Train Accuracy: 0.0515\n",
      "Computations for Epoch 1: 2.63e+14\n",
      "Val Loss: 4.0526, Val Accuracy: 0.0691\n",
      "Epoch 2/3\n",
      "--------------------\n",
      "Train Loss: 3.9412, Train Accuracy: 0.0832\n",
      "Computations for Epoch 2: 2.63e+14\n",
      "Val Loss: 4.3925, Val Accuracy: 0.0747\n",
      "Epoch 3/3\n",
      "--------------------\n",
      "Train Loss: 3.7488, Train Accuracy: 0.1174\n",
      "Computations for Epoch 3: 2.63e+14\n",
      "Val Loss: 3.8175, Val Accuracy: 0.1333\n",
      "Total Computations (FLOPs approximation): 7.89e+14\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Data transformations\n",
    "input_size = 224\n",
    "batch_size = 32\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "data_dir = './data/tiny-imagenet-200/train'\n",
    "full_dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])\n",
    "class_subset = 80\n",
    "\n",
    "targets = torch.tensor([sample[1] for sample in full_dataset.samples])\n",
    "indices = [i for i in range(len(targets)) if targets[i] < class_subset]\n",
    "subset_dataset = torch.utils.data.Subset(full_dataset, indices)\n",
    "\n",
    "train_size = int(0.8 * len(subset_dataset))\n",
    "val_size = len(subset_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(subset_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Define ResNet-50 model\n",
    "model = models.resnet50(pretrained=False)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, class_subset)  # Modify for 80 classes\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Training function with computation counter\n",
    "def train_model_with_computations(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    total_computations = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        epoch_computations = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Calculate FLOPs approximation\n",
    "            epoch_computations += inputs.size(0) * inputs.size(2) * inputs.size(3) * num_features * class_subset\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = correct / total\n",
    "        total_computations += epoch_computations\n",
    "\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}')\n",
    "        print(f'Computations for Epoch {epoch + 1}: {epoch_computations:.2e}')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_epoch_loss = val_loss / len(val_loader.dataset)\n",
    "        val_epoch_acc = val_correct / val_total\n",
    "        print(f'Val Loss: {val_epoch_loss:.4f}, Val Accuracy: {val_epoch_acc:.4f}')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f'Total Computations (FLOPs approximation): {total_computations:.2e}')\n",
    "    return total_computations\n",
    "\n",
    "# Train and compute\n",
    "total_computations = train_model_with_computations(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e23bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPQ Matrix Mean: -0.0005\n",
      "RPQ Matrix Variance: 1.0000\n",
      "Projected Output Shape: torch.Size([32, 2048])\n",
      "Projected Output Mean: -0.1055\n",
      "Projected Output Variance: 2027.4707\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to generate RPQ matrix\n",
    "def random_projection_matrix(input_dim, output_dim):\n",
    "    \"\"\"Generates a random projection matrix with mean=0 and variance=1.\"\"\"\n",
    "    return torch.randn(input_dim, output_dim).to(device)\n",
    "\n",
    "# Dimensions for RPQ\n",
    "input_dim = 2048  # Example input feature size\n",
    "output_dim = 2048  # Example output feature size\n",
    "\n",
    "# Generate the RPQ matrix\n",
    "rpq_matrix = random_projection_matrix(input_dim, output_dim)\n",
    "\n",
    "# Compute statistics\n",
    "mean = rpq_matrix.mean().item()\n",
    "variance = rpq_matrix.var().item()\n",
    "\n",
    "# Print results\n",
    "print(f\"RPQ Matrix Mean: {mean:.4f}\")\n",
    "print(f\"RPQ Matrix Variance: {variance:.4f}\")\n",
    "\n",
    "# Verify application with dummy input\n",
    "dummy_input = torch.randn(32, input_dim).to(device)  # Batch size of 32, input_dim features\n",
    "projected_output = torch.matmul(dummy_input, rpq_matrix)\n",
    "\n",
    "# Check shape and statistics of projected output\n",
    "print(f\"Projected Output Shape: {projected_output.shape}\")\n",
    "projected_mean = projected_output.mean().item()\n",
    "projected_variance = projected_output.var().item()\n",
    "print(f\"Projected Output Mean: {projected_mean:.4f}\")\n",
    "print(f\"Projected Output Variance: {projected_variance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbacf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
