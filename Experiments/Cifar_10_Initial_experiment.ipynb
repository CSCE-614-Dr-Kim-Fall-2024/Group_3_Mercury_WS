{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126432a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7ca4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212cfb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2507f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ab048d7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Epoch 1/1\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 1805\n",
      "First Layer->Cache_misses 8195\n",
      "TOTAL TIME TAKEN in EPOCH: 13.135185200007982 seconds\n",
      "TOTAL RPQ TIME: 1.7139770996873267 seconds\n",
      "CYCLES: 5910.833340003592*10e6\n",
      "Training complete!\n",
      "Average_Cache_hits : 1805.0\n",
      "Average_Cache_misses: 8195.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "CLOCK_SPEED = 450 #MHZ\n",
    "\n",
    "# 1. Hyperparameters\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Data Preprocessing: No resizing, keep original 32x32 size\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.RandomHorizontalFlip(p=0.5),       # Randomly flip the image horizontally with a probability of 50%\n",
    "    transforms.RandomRotation(degrees=15),        # Randomly rotate the image within Â±15 degrees\n",
    "    transforms.RandomResizedCrop(size=32, scale=(0.8, 1.0)),  # Random crop and resize back to 32x32\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),      # Randomly adjust brightness and contrast\n",
    "    transforms.ToTensor(),                        # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])   # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "# 3. Load CIFAR-10 Dataset\n",
    "full_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#full_test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 4. Filter Dataset for Autombile and Dogs\n",
    "def filter_Automobile_dogs(dataset):\n",
    "    targets = torch.tensor(dataset.targets)  # Convert labels to a tensor\n",
    "    mask = (targets == 1) | (targets == 5)  # Keep only labels 1 (automobile) and 5 (dog)\n",
    "    dataset.targets = targets[mask].tolist()  # Update targets\n",
    "    dataset.data = dataset.data[mask.numpy()]  # Update data\n",
    "    return dataset\n",
    "\n",
    "train_dataset = filter_Automobile_dogs(full_train_dataset)\n",
    "#test_dataset = filter_Automobile_dogs(full_test_dataset)\n",
    "\n",
    "# 5. Update Labels: Map [1, 5] -> [0, 1]\n",
    "def remap_labels(dataset):\n",
    "    dataset.targets = [0 if label == 1 else 1 for label in dataset.targets]  # Automobile = 0, Dog = 1\n",
    "    return dataset\n",
    "\n",
    "train_dataset = remap_labels(train_dataset)\n",
    "#test_dataset = remap_labels(test_dataset)\n",
    "\n",
    "# 6. Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "#outputs_final = {}\n",
    "total_cache_hits = 0\n",
    "total_cache_misses = 0\n",
    "total_rpq = 0\n",
    "\n",
    "\n",
    "random_rpq_matrix = torch.randn(1024, 20, device=device).uniform_(-1,1) # Move RPQ matrix to GPU #mean = 0 and var = 1\n",
    "\n",
    "# RPQ Function\n",
    "def rpq(input_vector, rows, columns):\n",
    "    flattened_vector = input_vector.view(input-1)\n",
    "    # Dot product of input vector and R\n",
    "    signature = torch.matmul(flattened_vector, random_rpq_matrix)\n",
    "\n",
    "    # Quantization -> sign-based\n",
    "    signature_quantized = torch.where(signature < 0, torch.tensor(1.0, device=signature.device), torch.tensor(0.0, device=signature.device))\n",
    "    return signature_quantized\n",
    "\n",
    "\n",
    "# 7. Define a Simple CNN\n",
    "class SimpleCNN_with_RPQ_Layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN_with_RPQ_Layer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 classes: automobile and dog\n",
    "        \n",
    "        self.mcache = {}\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0 \n",
    "        self.binary = ''\n",
    "    \n",
    "    def reset(self):\n",
    "        self.mcache.clear()\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0 \n",
    "        print(\"Mcache Reset\")\n",
    "        \n",
    "    def forward(self):\n",
    "        global total_cache_hits, total_cache_misses, total_rpq\n",
    "        #reset mcache, cache_hits and cache_misses\n",
    "        self.reset()\n",
    "        \n",
    "        # first conv layer\n",
    "        weights_conv1 = {}\n",
    "        #weights_conv2 = {}\n",
    "        \n",
    "        j = 0\n",
    "        for input_image, input_label in train_loader:\n",
    "            input_image = input_image.to(device)\n",
    "            # Generate RPQ signature and binary key\n",
    "            start_rpq = perf_counter()\n",
    "            rpq_signature_output = rpq(input_image, 1024, 20)# 1024 coz 32 * 32 (right now) , 30 columns coz signature length \n",
    "            end_rpq = perf_counter()\n",
    "            total_rpq += (end_rpq - start_rpq)\n",
    "            #Convert the binary tensor to a string representation of binary\n",
    "            self.binary_key = ''.join(map(str, rpq_signature_output.int().tolist()))  # tensor to list and then to string\n",
    "    \n",
    "            #cache mechanism\n",
    "            if self.binary_key in self.mcache:\n",
    "                self.cache_hits += 1\n",
    "                weights_conv1[j] = self.mcache[self.binary_key]\n",
    "            else :\n",
    "                self.cache_misses += 1\n",
    "                weights_conv1[j] = torch.relu(self.conv1(input_image))\n",
    "                self.mcache[self.binary_key] = weights_conv1[j]        \n",
    "            j += 1\n",
    "        \n",
    "        print(\"First Layer Training Complete\")\n",
    "        total_cache_hits += self.cache_hits\n",
    "        total_cache_misses += self.cache_misses\n",
    "        print(\"First layer->Cache_hits\", self.cache_hits)\n",
    "        print(\"First Layer->Cache_misses\", self.cache_misses)\n",
    "        \n",
    "#         # Second layer is continued using the output of the First conv layer (weights_conv1[]) \n",
    "#         j = 0\n",
    "#         print(\"WEIGHTS:\",len(weights_conv1))\n",
    "#         for i in range(0,len(weights_conv1[0])): # will iterate through 16 feature maps\n",
    "#             for j in range(0,len(weights_conv1[0][i])): # each input image 32*32\n",
    "#                 print(\"WEIGHTS_SHAPE:\",weights_conv1[0][i][j].shape)\n",
    "#                 # Generate RPQ signature and binary key\n",
    "#                 rpq_signature_output = rpq(weights_conv1[0][i][j], 1024, 20) # 1024 coz 32 * 32 (right now) , 20 columns coz signature length \n",
    "\n",
    "#                 # Convert the binary tensor to a string representation of binary\n",
    "#                 self.binary_key = ''.join(map(str, rpq_signature_output.tolist()))  # tensor to list and then to string\n",
    "                \n",
    "#                 if self.binary in self.mcache :\n",
    "#                     self.cache_hits += 1\n",
    "#                     weights_conv2[j] = self.mcache[i][self.binary_key]\n",
    "#                 else :\n",
    "#                     self.cache_misses += 1\n",
    "#                     weights_conv2[j] = self.pool(torch.relu(self.conv2(weights_conv1[i]))) \n",
    "#                     self.mcache[i][self.binary_key] = weights_conv2[i]\n",
    "#                 j += 1\n",
    "            \n",
    "#         print(\"Second layer Training Complete\")            \n",
    "#         total_cache_hits += self.cache_hits\n",
    "#         total_cache_misses += self.cache_misses\n",
    "#         print(\"Second layer->Cache_hits\", self.cache_hits)\n",
    "#         print(\"Second Layer->Cache_misses\", self.cache_misses)\n",
    "        \n",
    "        #The other layers(Pool,FC1,FC2) is continued using the outputs of the Second conv layer (weights_conv2[])\n",
    "        for i in range(0,len(weights_conv1)):\n",
    "            x = torch.relu(self.conv2(weights_conv1[i]))\n",
    "            x = self.pool(x)\n",
    "            x = x.view(-1, 32 * 8 * 8)\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "\n",
    "model = SimpleCNN_with_RPQ_Layer().to(device)  # Move model to GPU\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "# 8. Training Loop \n",
    "# Forward Propogation\n",
    "sync = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    start = perf_counter()\n",
    "    model()\n",
    "    end = perf_counter()\n",
    "    sync += (end - start)\n",
    "    print(f\"TOTAL TIME TAKEN in EPOCH: {end - start} seconds\")\n",
    "\n",
    "print(f\"TOTAL RPQ TIME: {total_rpq} seconds\")\n",
    "print(f\"CYCLES: {sync * CLOCK_SPEED}*10e6\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Average_Cache_hits :\", total_cache_hits/num_epochs)\n",
    "print(\"Average_Cache_misses:\", total_cache_misses/num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668c5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3529033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347422a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60c47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713dbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# loss calculation and Bqckward Propogation  \n",
    "    ##########################################################    \n",
    "        loss = criterion(outputs, input_label)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 10. Test the Model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776cb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8e25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
