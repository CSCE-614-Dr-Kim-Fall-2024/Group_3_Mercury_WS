{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d6e63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline system without WS:\n",
      "Input 0: Performing baseline computation.\n",
      "Input 1: Performing baseline computation.\n",
      "Input 2: Performing baseline computation.\n",
      "Input 3: Performing baseline computation.\n",
      "Input 4: Performing baseline computation.\n",
      "Input 5: Performing baseline computation.\n",
      "Input 6: Performing baseline computation.\n",
      "Input 7: Performing baseline computation.\n",
      "Input 8: Performing baseline computation.\n",
      "Input 9: Performing baseline computation.\n",
      "\n",
      "Training system with WS dataflow using RPQ and MCACHE:\n",
      "Input 0: No similarity found. Performing computation.\n",
      "Input 1: No similarity found. Performing computation.\n",
      "Input 2: No similarity found. Performing computation.\n",
      "Input 3: No similarity found. Performing computation.\n",
      "Input 4: Similarity found! Skipping redundant computation.\n",
      "Input 5: Similarity found! Skipping redundant computation.\n",
      "Input 6: Similarity found! Skipping redundant computation.\n",
      "Input 7: No similarity found. Performing computation.\n",
      "Input 8: No similarity found. Performing computation.\n",
      "Input 9: No similarity found. Performing computation.\n",
      "\n",
      "Total computations in baseline system: 10\n",
      "Total computations in WS system with RPQ/MCACHE: 7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "class RPQ:\n",
    "    def __init__(self, input_dim, projection_dim, quant_bits):\n",
    "        \"\"\"\n",
    "        Initialize the RPQ module.\n",
    "        :param input_dim: Dimensionality of the input vectors (flattened).\n",
    "        :param projection_dim: Dimensionality after random projection.\n",
    "        :param quant_bits: Number of bits for quantization.\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.projection_dim = projection_dim\n",
    "        self.quant_bits = quant_bits\n",
    "        \n",
    "        # Random projection matrix (Gaussian random matrix)\n",
    "        self.projection_matrix = torch.randn(projection_dim, input_dim)\n",
    "        \n",
    "    def random_projection(self, x):\n",
    "        \"\"\"\n",
    "        Perform random projection on the input vector.\n",
    "        :param x: Input tensor of shape (batch_size, input_dim).\n",
    "        :return: Projected tensor of shape (batch_size, projection_dim).\n",
    "        \"\"\"\n",
    "        return torch.matmul(x, self.projection_matrix.T)\n",
    "    \n",
    "    def quantize(self, x):\n",
    "        \"\"\"\n",
    "        Quantize the projected vector into a bit sequence.\n",
    "        :param x: Projected tensor of shape (batch_size, projection_dim).\n",
    "        :return: Quantized bit sequence of shape (batch_size, projection_dim).\n",
    "        \"\"\"\n",
    "        # Normalize the projected values to the range [0, 1]\n",
    "        x_min = x.min(dim=1, keepdim=True)[0]\n",
    "        x_max = x.max(dim=1, keepdim=True)[0]\n",
    "        x_normalized = (x - x_min) / (x_max - x_min + 1e-8)\n",
    "        \n",
    "        # Quantize to a discrete set of values based on the number of bits\n",
    "        quantized_x = torch.floor(x_normalized * (2 ** self.quant_bits)).int()\n",
    "        \n",
    "        return quantized_x\n",
    "    \n",
    "    def compute_signature(self, x):\n",
    "        \"\"\"\n",
    "        Compute the RPQ signature for the input vector.\n",
    "        :param x: Input tensor of shape (batch_size, input_dim).\n",
    "        :return: Signature tensor of shape (batch_size, projection_dim).\n",
    "        \"\"\"\n",
    "        projected_x = self.random_projection(x)\n",
    "        signature = self.quantize(projected_x)\n",
    "        \n",
    "        return signature\n",
    "\n",
    "# Cache mechanism to store and compare signatures\n",
    "class InputSimilarityCache:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store signatures and their corresponding results\n",
    "        self.cache = {}\n",
    "    \n",
    "    def check_similarity(self, signature):\n",
    "        \"\"\"\n",
    "        Check if a given signature is already in the cache.\n",
    "        :param signature: The signature to check.\n",
    "        :return: Boolean indicating whether a similar signature exists in cache.\n",
    "                 If found, return True and the cached result; otherwise return False.\n",
    "        \"\"\"\n",
    "        sig_tuple = tuple(signature.view(-1).tolist())  # Convert tensor to tuple for hashing\n",
    "        \n",
    "        if sig_tuple in self.cache:\n",
    "            return True, self.cache[sig_tuple]\n",
    "        \n",
    "        return False, None\n",
    "    \n",
    "    def store_signature(self, signature, result):\n",
    "        \"\"\"\n",
    "        Store a new signature and its corresponding result in cache.\n",
    "        :param signature: The signature to store.\n",
    "        :param result: The result associated with this signature.\n",
    "        \"\"\"\n",
    "        sig_tuple = tuple(signature.view(-1).tolist())  # Convert tensor to tuple for hashing\n",
    "        self.cache[sig_tuple] = result\n",
    "\n",
    "# Define ResNet50 model from scratch for training purposes\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        \n",
    "        # Use torchvision's ResNet50 architecture but without pretrained weights\n",
    "        self.model = models.resnet50(pretrained=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Function to run ResNet50 training with or without RPQ/MCACHE\n",
    "def train_resnet50_with_rpq(inputs, labels, rpq=None, cache=None):\n",
    "    # Define ResNet50 model\n",
    "    resnet50 = ResNet50().train()\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(resnet50.parameters(), lr=0.001)\n",
    "    \n",
    "    total_computations = 0  # Track total computations\n",
    "    \n",
    "    for i in range(inputs.size(0)):\n",
    "        \n",
    "        if rpq is not None and cache is not None:\n",
    "            # Flatten each image before computing RPQ signature\n",
    "            flattened_input = inputs[i].view(1, -1)  # Flatten image from [3x224x224] to [1x150528]\n",
    "            \n",
    "            # Compute RPQ signature for each flattened input vector\n",
    "            signature = rpq.compute_signature(flattened_input)\n",
    "            \n",
    "            # Check if a similar input has been processed before\n",
    "            is_similar, cached_result = cache.check_similarity(signature)\n",
    "            \n",
    "            if is_similar:\n",
    "                print(f\"Input {i}: Similarity found! Skipping redundant computation.\")\n",
    "                continue  # Skip forward/backward pass\n",
    "            \n",
    "            else:\n",
    "                print(f\"Input {i}: No similarity found. Performing computation.\")\n",
    "                total_computations += 1\n",
    "                \n",
    "                # Forward pass through ResNet50\n",
    "                outputs = resnet50(inputs[i].unsqueeze(0))\n",
    "                \n",
    "                # Compute loss and perform backward pass\n",
    "                loss = criterion(outputs, labels[i].unsqueeze(0))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Store result in cache along with its signature\n",
    "                cache.store_signature(signature, outputs)\n",
    "        \n",
    "        else:\n",
    "            print(f\"Input {i}: Performing baseline computation.\")\n",
    "            total_computations += 1\n",
    "            \n",
    "            # Forward pass through ResNet50 without caching\n",
    "            outputs = resnet50(inputs[i].unsqueeze(0))\n",
    "            \n",
    "            # Compute loss and perform backward pass\n",
    "            loss = criterion(outputs, labels[i].unsqueeze(0))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return total_computations\n",
    "\n",
    "# Example usage with controlled perturbations\n",
    "if __name__ == \"__main__\":\n",
    "    # Define dimensions for flattening images (3x224x224 -> 150528)\n",
    "    input_dim = 224 * 224 * 3  # Input dimension for ResNet50 images (3x224x224)\n",
    "    projection_dim = 100  # Projected dimension for RPQ\n",
    "    quant_bits = 4  # Number of bits for quantization\n",
    "    \n",
    "    # Create an instance of RPQ and cache\n",
    "    rpq = RPQ(input_dim=input_dim, projection_dim=projection_dim, quant_bits=quant_bits)\n",
    "    cache = InputSimilarityCache()\n",
    "    \n",
    "    # Generate a base image and create slightly perturbed versions of it\n",
    "    batch_size = 10\n",
    "    num_classes = 1000  # Number of classes in ImageNet dataset\n",
    "    \n",
    "    base_input = torch.randn(3, 224, 224)  # Base image\n",
    "    \n",
    "    # Create perturbed versions by adding small noise to the base image\n",
    "    inputs = base_input + 0.01 * torch.randn(batch_size, 3, 224, 224)  \n",
    "    labels = torch.randint(0, num_classes, (batch_size,), dtype=torch.long)  # Random labels\n",
    "    \n",
    "    print(\"Training baseline system without WS:\")\n",
    "    baseline_computations = train_resnet50_with_rpq(inputs.clone(), labels)  # Baseline system without WS\n",
    "    \n",
    "    print(\"\\nTraining system with WS dataflow using RPQ and MCACHE:\")\n",
    "    ws_computations = train_resnet50_with_rpq(inputs.clone(), labels, rpq=rpq, cache=cache)  # System with WS dataflow\n",
    "    \n",
    "    print(f\"\\nTotal computations in baseline system: {baseline_computations}\")\n",
    "    print(f\"Total computations in WS system with RPQ/MCACHE: {ws_computations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20238ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline system without WS:\n",
      "Input Vector 0: \n",
      "[ 1.77830805  0.39673966  0.96275103 ...  1.5456486   1.77904098\n",
      " -0.41382903]\n",
      "Input 0: Performing baseline computation.\n",
      "Input Vector 1: \n",
      "[ 1.7531359   0.38576447  0.97940135 ...  1.569255    1.76757386\n",
      " -0.4286924 ]\n",
      "Input 1: Performing baseline computation.\n",
      "Input Vector 2: \n",
      "[ 1.7631238   0.39680271  0.9848966  ...  1.544547    1.78288554\n",
      " -0.42692535]\n",
      "Input 2: Performing baseline computation.\n",
      "Input Vector 3: \n",
      "[ 1.76162675  0.39850917  0.98969458 ...  1.5375335   1.77245231\n",
      " -0.40943078]\n",
      "Input 3: Performing baseline computation.\n",
      "Input Vector 4: \n",
      "[ 1.76060868  0.39994359  0.97024779 ...  1.57119221  1.7717411\n",
      " -0.41727425]\n",
      "Input 4: Performing baseline computation.\n",
      "Input Vector 5: \n",
      "[ 1.7737314   0.39427718  0.97677938 ...  1.54062138  1.77557746\n",
      " -0.41983422]\n",
      "Input 5: Performing baseline computation.\n",
      "Input Vector 6: \n",
      "[ 1.76100928  0.4059369   0.9712469  ...  1.55671905  1.75731445\n",
      " -0.4119689 ]\n",
      "Input 6: Performing baseline computation.\n",
      "Input Vector 7: \n",
      "[ 1.75702411  0.3770722   0.96350402 ...  1.56415792  1.76572149\n",
      " -0.42561862]\n",
      "Input 7: Performing baseline computation.\n",
      "Input Vector 8: \n",
      "[ 1.75861085  0.39092115  0.9776417  ...  1.55118752  1.78077768\n",
      " -0.42661646]\n",
      "Input 8: Performing baseline computation.\n",
      "Input Vector 9: \n",
      "[ 1.77802338  0.38989344  0.97356263 ...  1.56435906  1.78256479\n",
      " -0.41651399]\n",
      "Input 9: Performing baseline computation.\n",
      "\n",
      "Training system with WS dataflow using RPQ and MCACHE:\n",
      "Input Vector 0: \n",
      "[ 1.77830805  0.39673966  0.96275103 ...  1.5456486   1.77904098\n",
      " -0.41382903]\n",
      "Input 0: No similarity found. Performing computation.\n",
      "Input Vector 1: \n",
      "[ 1.7531359   0.38576447  0.97940135 ...  1.569255    1.76757386\n",
      " -0.4286924 ]\n",
      "Input 1: No similarity found. Performing computation.\n",
      "Input Vector 2: \n",
      "[ 1.7631238   0.39680271  0.9848966  ...  1.544547    1.78288554\n",
      " -0.42692535]\n",
      "Input 2: No similarity found. Performing computation.\n",
      "Input Vector 3: \n",
      "[ 1.76162675  0.39850917  0.98969458 ...  1.5375335   1.77245231\n",
      " -0.40943078]\n",
      "Input 3: No similarity found. Performing computation.\n",
      "Input Vector 4: \n",
      "[ 1.76060868  0.39994359  0.97024779 ...  1.57119221  1.7717411\n",
      " -0.41727425]\n",
      "Input 4: No similarity found. Performing computation.\n",
      "Input Vector 5: \n",
      "[ 1.7737314   0.39427718  0.97677938 ...  1.54062138  1.77557746\n",
      " -0.41983422]\n",
      "Input 5: No similarity found. Performing computation.\n",
      "Input Vector 6: \n",
      "[ 1.76100928  0.4059369   0.9712469  ...  1.55671905  1.75731445\n",
      " -0.4119689 ]\n",
      "Input 6: No similarity found. Performing computation.\n",
      "Input Vector 7: \n",
      "[ 1.75702411  0.3770722   0.96350402 ...  1.56415792  1.76572149\n",
      " -0.42561862]\n",
      "Input 7: No similarity found. Performing computation.\n",
      "Input Vector 8: \n",
      "[ 1.75861085  0.39092115  0.9776417  ...  1.55118752  1.78077768\n",
      " -0.42661646]\n",
      "Input 8: No similarity found. Performing computation.\n",
      "Input Vector 9: \n",
      "[ 1.77802338  0.38989344  0.97356263 ...  1.56435906  1.78256479\n",
      " -0.41651399]\n",
      "Input 9: Similarity found! Skipping redundant computation.\n",
      "\n",
      "Total computations in baseline system: 10\n",
      "Total computations in WS system with RPQ/MCACHE: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RPQ:\n",
    "    def __init__(self, input_dim, projection_dim, quant_bits):\n",
    "        \"\"\"\n",
    "        Initialize the RPQ module.\n",
    "        :param input_dim: Dimensionality of the input vectors (flattened).\n",
    "        :param projection_dim: Dimensionality after random projection.\n",
    "        :param quant_bits: Number of bits for quantization.\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.projection_dim = projection_dim\n",
    "        self.quant_bits = quant_bits\n",
    "        \n",
    "        # Random projection matrix (Gaussian random matrix)\n",
    "        self.projection_matrix = np.random.randn(projection_dim, input_dim)\n",
    "        \n",
    "    def random_projection(self, x):\n",
    "        \"\"\"\n",
    "        Perform random projection on the input vector.\n",
    "        :param x: Input tensor of shape (batch_size, input_dim).\n",
    "        :return: Projected tensor of shape (batch_size, projection_dim).\n",
    "        \"\"\"\n",
    "        return np.dot(x, self.projection_matrix.T)\n",
    "    \n",
    "    def quantize(self, x):\n",
    "        \"\"\"\n",
    "        Quantize the projected vector into a bit sequence.\n",
    "        :param x: Projected tensor of shape (batch_size, projection_dim).\n",
    "        :return: Quantized bit sequence of shape (batch_size, projection_dim).\n",
    "        \"\"\"\n",
    "        x_min = np.min(x, axis=1, keepdims=True)\n",
    "        x_max = np.max(x, axis=1, keepdims=True)\n",
    "        x_normalized = (x - x_min) / (x_max - x_min + 1e-8)\n",
    "        \n",
    "        # Quantize to a discrete set of values based on the number of bits\n",
    "        quantized_x = np.floor(x_normalized * (2 ** self.quant_bits)).astype(int)\n",
    "        \n",
    "        return quantized_x\n",
    "    \n",
    "    def compute_signature(self, x):\n",
    "        \"\"\"\n",
    "        Compute the RPQ signature for the input vector.\n",
    "        :param x: Input tensor of shape (batch_size, input_dim).\n",
    "        :return: Signature tensor of shape (batch_size, projection_dim).\n",
    "        \"\"\"\n",
    "        projected_x = self.random_projection(x)\n",
    "        signature = self.quantize(projected_x)\n",
    "        \n",
    "        return signature\n",
    "\n",
    "# Cache mechanism to store and compare signatures\n",
    "class InputSimilarityCache:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store signatures and their corresponding results\n",
    "        self.cache = {}\n",
    "    \n",
    "    def check_similarity(self, signature):\n",
    "        \"\"\"\n",
    "        Check if a given signature is already in the cache.\n",
    "        :param signature: The signature to check.\n",
    "        :return: Boolean indicating whether a similar signature exists in cache.\n",
    "                 If found, return True and the cached result; otherwise return False.\n",
    "        \"\"\"\n",
    "        sig_tuple = tuple(signature.flatten())  # Convert tensor to tuple for hashing\n",
    "        \n",
    "        if sig_tuple in self.cache:\n",
    "            return True, self.cache[sig_tuple]\n",
    "        \n",
    "        return False, None\n",
    "    \n",
    "    def store_signature(self, signature, result):\n",
    "        \"\"\"\n",
    "        Store a new signature and its corresponding result in cache.\n",
    "        :param signature: The signature to store.\n",
    "        :param result: The result associated with this signature.\n",
    "        \"\"\"\n",
    "        sig_tuple = tuple(signature.flatten())  # Convert tensor to tuple for hashing\n",
    "        self.cache[sig_tuple] = result\n",
    "\n",
    "# Function to run ResNet50 training with or without RPQ/MCACHE\n",
    "def train_resnet50_with_rpq(inputs, labels, rpq=None, cache=None):\n",
    "    total_computations = 0  # Track total computations\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        \n",
    "        print(f\"Input Vector {i}: \\n{inputs[i].flatten()}\")  # Print flattened input vector\n",
    "        \n",
    "        if rpq is not None and cache is not None:\n",
    "            # Flatten each image before computing RPQ signature\n",
    "            flattened_input = inputs[i].flatten()  # Flatten image from [3x224x224] to [150528]\n",
    "            \n",
    "            # Compute RPQ signature for each flattened input vector\n",
    "            signature = rpq.compute_signature(flattened_input[np.newaxis, :])\n",
    "            \n",
    "            # Check if a similar input has been processed before\n",
    "            is_similar, cached_result = cache.check_similarity(signature)\n",
    "            \n",
    "            if is_similar:\n",
    "                print(f\"Input {i}: Similarity found! Skipping redundant computation.\")\n",
    "                continue  # Skip forward/backward pass\n",
    "            \n",
    "            else:\n",
    "                print(f\"Input {i}: No similarity found. Performing computation.\")\n",
    "                total_computations += 1\n",
    "                \n",
    "                # Simulate output computation and loss calculation\n",
    "                generated_output = np.random.randn(1, 1000)  # Assuming 1000 classes\n",
    "                loss = np.random.rand()  # Simulating loss computation\n",
    "                \n",
    "                # Store result in cache along with its signature\n",
    "                cache.store_signature(signature, generated_output)\n",
    "        \n",
    "        else:\n",
    "            print(f\"Input {i}: Performing baseline computation.\")\n",
    "            total_computations += 1\n",
    "            \n",
    "            # Simulate output computation and loss calculation\n",
    "            generated_output = np.random.randn(1, 1000)  # Assuming 1000 classes\n",
    "            loss = np.random.rand()  # Simulating loss computation\n",
    "    \n",
    "    return total_computations\n",
    "\n",
    "# Visualization function for computations comparison\n",
    "def visualize_computations(baseline_count, ws_count):\n",
    "    labels = ['Baseline', 'WS Dataflow']\n",
    "    counts = [baseline_count, ws_count]\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(labels, counts, color=['blue', 'orange'])\n",
    "    plt.title('Computations in Baseline vs WS Dataflow')\n",
    "    plt.ylabel('Total Computations')\n",
    "    plt.ylim(0, max(counts) + 5)\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with controlled perturbations and visualization\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "    \n",
    "    batch_size = 10\n",
    "    num_classes = 1000\n",
    "    \n",
    "    # Generate a base image and create slightly perturbed versions of it\n",
    "    base_input = np.random.randn(3, 224, 224)  \n",
    "    inputs = base_input + 0.01 * np.random.randn(batch_size, 3, 224, 224)  \n",
    "    labels = np.random.randint(0, num_classes, batch_size)  \n",
    "    \n",
    "    print(\"Training baseline system without WS:\")\n",
    "    baseline_computations = train_resnet50_with_rpq(inputs.copy(), labels)  \n",
    "    \n",
    "    print(\"\\nTraining system with WS dataflow using RPQ and MCACHE:\")\n",
    "    rpq = RPQ(input_dim=3*224*224, projection_dim=100, quant_bits=4)\n",
    "    cache = InputSimilarityCache()\n",
    "    \n",
    "    ws_computations = train_resnet50_with_rpq(inputs.copy(), labels.copy(), rpq=rpq, cache=cache)  \n",
    "    \n",
    "    print(f\"\\nTotal computations in baseline system: {baseline_computations}\")\n",
    "    print(f\"Total computations in WS system with RPQ/MCACHE: {ws_computations}\")\n",
    "    \n",
    "    visualize_computations(baseline_computations, ws_computations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeccbdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline system without WS:\n",
      "Input 0: Performing baseline computation.\n",
      "Input 1: Performing baseline computation.\n",
      "Input 2: Performing baseline computation.\n",
      "Input 3: Performing baseline computation.\n",
      "Input 4: Performing baseline computation.\n",
      "Input 5: Performing baseline computation.\n",
      "Input 6: Performing baseline computation.\n",
      "Input 7: Performing baseline computation.\n",
      "Input 8: Performing baseline computation.\n",
      "Input 9: Performing baseline computation.\n",
      "\n",
      "Training system with WS dataflow using RPQ and MCACHE:\n",
      "Input 0: No similarity found. Performing computation.\n",
      "Input 1: No similarity found. Performing computation.\n",
      "Input 2: No similarity found. Performing computation.\n",
      "Input 3: No similarity found. Performing computation.\n",
      "Input 4: No similarity found. Performing computation.\n",
      "Input 5: No similarity found. Performing computation.\n",
      "Input 6: Similarity found! Skipping redundant computation.\n",
      "Input 7: No similarity found. Performing computation.\n",
      "Input 8: No similarity found. Performing computation.\n",
      "Input 9: Similarity found! Skipping redundant computation.\n",
      "\n",
      "Total computations in baseline system: 10\n",
      "Total computations in WS system with RPQ/MCACHE: 8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "class RPQ:\n",
    "    def __init__(self, input_dim, projection_dim, quant_bits):\n",
    "        \"\"\"\n",
    "        Initialize the RPQ module.\n",
    "        :param input_dim: Dimensionality of the input vectors (flattened).\n",
    "        :param projection_dim: Dimensionality after random projection.\n",
    "        :param quant_bits: Number of bits for quantization.\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.projection_dim = projection_dim\n",
    "        self.quant_bits = quant_bits\n",
    "        \n",
    "        # Random projection matrix (Gaussian random matrix)\n",
    "        self.projection_matrix = torch.randn(projection_dim, input_dim)\n",
    "        \n",
    "    def random_projection(self, x):\n",
    "        \"\"\"\n",
    "        Perform random projection on the input vector.\n",
    "        :param x: Input tensor of shape (batch_size, input_dim).\n",
    "        :return: Projected tensor of shape (batch_size, projection_dim).\n",
    "        \"\"\"\n",
    "        return torch.matmul(x, self.projection_matrix.T)\n",
    "    \n",
    "    def quantize(self, x):\n",
    "        \"\"\"\n",
    "        Quantize the projected vector into a bit sequence.\n",
    "        :param x: Projected tensor of shape (batch_size, projection_dim).\n",
    "        :return: Quantized bit sequence of shape (batch_size, projection_dim).\n",
    "        \"\"\"\n",
    "        # Normalize the projected values to the range [0, 1]\n",
    "        x_min = x.min(dim=1, keepdim=True)[0]\n",
    "        x_max = x.max(dim=1, keepdim=True)[0]\n",
    "        x_normalized = (x - x_min) / (x_max - x_min + 1e-8)\n",
    "        \n",
    "        # Quantize to a discrete set of values based on the number of bits\n",
    "        quantized_x = torch.floor(x_normalized * (2 ** self.quant_bits)).int()\n",
    "        \n",
    "        return quantized_x\n",
    "    \n",
    "    def compute_signature(self, x):\n",
    "        \"\"\"\n",
    "        Compute the RPQ signature for the input vector.\n",
    "        :param x: Input tensor of shape (batch_size, input_dim).\n",
    "        :return: Signature tensor of shape (batch_size, projection_dim).\n",
    "        \"\"\"\n",
    "        projected_x = self.random_projection(x)\n",
    "        signature = self.quantize(projected_x)\n",
    "        \n",
    "        return signature\n",
    "\n",
    "# Cache mechanism to store and compare signatures\n",
    "class InputSimilarityCache:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store signatures and their corresponding results\n",
    "        self.cache = {}\n",
    "    \n",
    "    def check_similarity(self, signature):\n",
    "        \"\"\"\n",
    "        Check if a given signature is already in the cache.\n",
    "        :param signature: The signature to check.\n",
    "        :return: Boolean indicating whether a similar signature exists in cache.\n",
    "                 If found, return True and the cached result; otherwise return False.\n",
    "        \"\"\"\n",
    "        sig_tuple = tuple(signature.view(-1).tolist())  # Convert tensor to tuple for hashing\n",
    "        \n",
    "        if sig_tuple in self.cache:\n",
    "            return True, self.cache[sig_tuple]\n",
    "        \n",
    "        # Check for similar signatures with tolerance\n",
    "        for cached_signature, result in self.cache.items():\n",
    "            similarity = torch.sum(torch.abs(signature - torch.tensor(cached_signature)))\n",
    "            if similarity.item() < 0.1:  # Set a threshold for similarity\n",
    "                return True, result\n",
    "        \n",
    "        return False, None\n",
    "    \n",
    "    def store_signature(self, signature, result):\n",
    "        \"\"\"\n",
    "        Store a new signature and its corresponding result in cache.\n",
    "        :param signature: The signature to store.\n",
    "        :param result: The result associated with this signature.\n",
    "        \"\"\"\n",
    "        sig_tuple = tuple(signature.view(-1).tolist())  # Convert tensor to tuple for hashing\n",
    "        self.cache[sig_tuple] = result\n",
    "\n",
    "# Define ResNet50 model from scratch for training purposes\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        \n",
    "        # Use torchvision's ResNet50 architecture but without pretrained weights\n",
    "        self.model = models.resnet50(pretrained=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Function to run ResNet50 training with or without RPQ/MCACHE\n",
    "def train_resnet50_with_rpq(inputs, labels, rpq=None, cache=None):\n",
    "    # Define ResNet50 model\n",
    "    resnet50 = ResNet50().train()\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(resnet50.parameters(), lr=0.001)\n",
    "    \n",
    "    total_computations = 0  # Track total computations\n",
    "    \n",
    "    for i in range(inputs.size(0)):\n",
    "        \n",
    "        if rpq is not None and cache is not None:\n",
    "            # Flatten each image before computing RPQ signature\n",
    "            flattened_input = inputs[i].view(1, -1)  # Flatten image from [3x224x224] to [1x150528]\n",
    "            \n",
    "            # Compute RPQ signature for each flattened input vector\n",
    "            signature = rpq.compute_signature(flattened_input)\n",
    "            \n",
    "            # Check if a similar input has been processed before\n",
    "            is_similar, cached_result = cache.check_similarity(signature)\n",
    "            \n",
    "            if is_similar:\n",
    "                print(f\"Input {i}: Similarity found! Skipping redundant computation.\")\n",
    "                continue  # Skip forward/backward pass\n",
    "            \n",
    "            else:\n",
    "                print(f\"Input {i}: No similarity found. Performing computation.\")\n",
    "                total_computations += 1\n",
    "                \n",
    "                # Forward pass through ResNet50\n",
    "                outputs = resnet50(inputs[i].unsqueeze(0))\n",
    "                \n",
    "                # Compute loss and perform backward pass\n",
    "                loss = criterion(outputs, labels[i].unsqueeze(0))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Store result in cache along with its signature\n",
    "                cache.store_signature(signature, outputs)\n",
    "        \n",
    "        else:\n",
    "            print(f\"Input {i}: Performing baseline computation.\")\n",
    "            total_computations += 1\n",
    "            \n",
    "            # Forward pass through ResNet50 without caching\n",
    "            outputs = resnet50(inputs[i].unsqueeze(0))\n",
    "            \n",
    "            # Compute loss and perform backward pass\n",
    "            loss = criterion(outputs, labels[i].unsqueeze(0))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return total_computations\n",
    "\n",
    "# Example usage with controlled perturbations\n",
    "if __name__ == \"__main__\":\n",
    "    # Define dimensions for flattening images (3x224x224 -> 150528)\n",
    "    input_dim = 224 * 224 * 3  # Input dimension for ResNet50 images (3x224x224)\n",
    "    projection_dim = 100  # Projected dimension for RPQ\n",
    "    quant_bits = 4  # Number of bits for quantization\n",
    "    \n",
    "    # Create an instance of RPQ and cache\n",
    "    rpq = RPQ(input_dim=input_dim, projection_dim=projection_dim, quant_bits=quant_bits)\n",
    "    cache = InputSimilarityCache()\n",
    "    \n",
    "    # Generate a base image and create slightly perturbed versions of it\n",
    "    batch_size = 10\n",
    "    num_classes = 1000  # Number of classes in ImageNet dataset\n",
    "    \n",
    "    base_input = torch.randn(3, 224, 224)  # Base image\n",
    "    \n",
    "    # Create perturbed versions by adding small noise to the base image\n",
    "    inputs = base_input + 0.01 * torch.randn(batch_size, 3, 224, 224)  \n",
    "    labels = torch.randint(0, num_classes, (batch_size,), dtype=torch.long)  # Random labels\n",
    "    \n",
    "    print(\"Training baseline system without WS:\")\n",
    "    baseline_computations = train_resnet50_with_rpq(inputs.clone(), labels)  # Baseline system without WS\n",
    "    \n",
    "    print(\"\\nTraining system with WS dataflow using RPQ and MCACHE:\")\n",
    "    ws_computations = train_resnet50_with_rpq(inputs.clone(), labels, rpq=rpq, cache=cache)  # System with WS dataflow\n",
    "    \n",
    "    print(f\"\\nTotal computations in baseline system: {baseline_computations}\")\n",
    "    print(f\"Total computations in WS system with RPQ/MCACHE: {ws_computations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8e8fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishw\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Training with RPQ and cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishw\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "c:\\users\\vishw\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Training Accuracy: 16.28%\n",
      "Epoch 1/3, Validation Accuracy: 22.96%\n",
      "Epoch 2/3, Training Accuracy: 26.90%\n",
      "Epoch 2/3, Validation Accuracy: 32.00%\n",
      "Epoch 3/3, Training Accuracy: 35.01%\n",
      "Epoch 3/3, Validation Accuracy: 36.99%\n",
      "Total computations with RPQ: 4689\n",
      "Training without RPQ...\n",
      "Epoch 1/3, Training Accuracy: 17.32%\n",
      "Epoch 1/3, Validation Accuracy: 21.48%\n",
      "Epoch 2/3, Training Accuracy: 26.19%\n",
      "Epoch 2/3, Validation Accuracy: 32.27%\n",
      "Epoch 3/3, Training Accuracy: 36.15%\n",
      "Epoch 3/3, Validation Accuracy: 36.89%\n",
      "Total computations without RPQ: 4689\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# Function to download and extract CIFAR-10 dataset\n",
    "def download_and_extract_cifar10(download_dir='data', url='https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'):\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "    \n",
    "    # Download the dataset if it's not already present\n",
    "    dataset_path = os.path.join(download_dir, 'cifar-10-python.tar.gz')\n",
    "    \n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(f\"Downloading CIFAR-10 dataset from {url}...\")\n",
    "        urllib.request.urlretrieve(url, dataset_path)\n",
    "    \n",
    "    # Extract if not already extracted\n",
    "    extracted_dir = os.path.join(download_dir, 'cifar-10-batches-py')\n",
    "    \n",
    "    if not os.path.exists(extracted_dir):\n",
    "        print(f\"Extracting CIFAR-10 dataset...\")\n",
    "        with tarfile.open(dataset_path, 'r:gz') as tar_ref:\n",
    "            tar_ref.extractall(download_dir)\n",
    "\n",
    "# RPQ module for random projection and quantization\n",
    "class RPQ:\n",
    "    def __init__(self, input_dim, projection_dim, quant_bits, device):\n",
    "        self.device = device\n",
    "        self.input_dim = input_dim\n",
    "        self.projection_dim = projection_dim\n",
    "        self.quant_bits = quant_bits\n",
    "        self.projection_matrix = torch.randn(projection_dim, input_dim, device=device)\n",
    "        \n",
    "    def random_projection(self, x):\n",
    "        return torch.matmul(x, self.projection_matrix.T)\n",
    "    \n",
    "    def quantize(self, x):\n",
    "        x_min = x.min(dim=1, keepdim=True)[0]\n",
    "        x_max = x.max(dim=1, keepdim=True)[0]\n",
    "        x_normalized = (x - x_min) / (x_max - x_min + 1e-8)\n",
    "        quantized_x = torch.floor(x_normalized * (2 ** self.quant_bits)).int()\n",
    "        return quantized_x\n",
    "    \n",
    "    def compute_signature(self, x):\n",
    "        projected_x = self.random_projection(x)\n",
    "        signature = self.quantize(projected_x)\n",
    "        return signature\n",
    "\n",
    "# Model and training function\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# A simple input similarity cache\n",
    "class InputSimilarityCache:\n",
    "    def __init__(self):\n",
    "        self.cache = {}\n",
    "\n",
    "    def check_similarity(self, signature):\n",
    "        signature_tuple = tuple(signature.view(-1).tolist())\n",
    "        return signature_tuple in self.cache, self.cache.get(signature_tuple)\n",
    "\n",
    "    def store_signature(self, signature, result):\n",
    "        signature_tuple = tuple(signature.view(-1).tolist())\n",
    "        self.cache[signature_tuple] = result\n",
    "\n",
    "def train_resnet50_with_rpq(trainloader, validloader, rpq=None, cache=None, num_epochs=5, device='cpu'):\n",
    "    resnet50 = ResNet50().to(device)  # Ensure the model is on the correct device\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(resnet50.parameters(), lr=0.001)\n",
    "    \n",
    "    total_computations = 0  # Track total computations\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Ensure inputs and labels are on the same device\n",
    "            \n",
    "            if rpq is not None and cache is not None:\n",
    "                flattened_input = inputs.view(inputs.size(0), -1).to(device)  # Move to the same device as the model\n",
    "                signature = rpq.compute_signature(flattened_input)\n",
    "                is_similar, cached_result = cache.check_similarity(signature)\n",
    "                \n",
    "                if is_similar:\n",
    "                    continue  # Skip if similar signature is found\n",
    "                else:\n",
    "                    total_computations += 1\n",
    "                    outputs = resnet50(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    cache.store_signature(signature, outputs)\n",
    "            else:\n",
    "                total_computations += 1  # Increment for each forward pass\n",
    "                outputs = resnet50(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Accuracy: {train_acc:.2f}%')\n",
    "        \n",
    "        # Validation Loop\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        resnet50.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)  # Ensure inputs and labels are on the same device\n",
    "                outputs = resnet50(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Accuracy: {val_acc:.2f}%')\n",
    "        \n",
    "    return total_computations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Download CIFAR-10\n",
    "    download_and_extract_cifar10()\n",
    "\n",
    "    # Set up data transforms and loaders\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "    # Load CIFAR-10 dataset\n",
    "    trainset = datasets.CIFAR10(root='data', train=True, download=False, transform=transform)\n",
    "    testset = datasets.CIFAR10(root='data', train=False, download=False, transform=transform)\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "    validloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # RPQ and cache setup\n",
    "    input_dim = 32 * 32 * 3  # CIFAR-10 image size (32x32x3)\n",
    "    projection_dim = 100  # Projected dimension for RPQ\n",
    "    quant_bits = 4  # Number of bits for quantization\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    rpq = RPQ(input_dim=input_dim, projection_dim=projection_dim, quant_bits=quant_bits, device=device)\n",
    "    cache = InputSimilarityCache()\n",
    "\n",
    "    print(f\"Training on {device}\")\n",
    "    \n",
    "    # Train with RPQ and cache\n",
    "    print(\"Training with RPQ and cache...\")\n",
    "    computations_with_rpq = train_resnet50_with_rpq(trainloader, validloader, rpq=rpq, cache=cache, num_epochs=3, device=device)\n",
    "    print(f\"Total computations with RPQ: {computations_with_rpq}\")\n",
    "    \n",
    "    # Train without RPQ\n",
    "    print(\"Training without RPQ...\")\n",
    "    computations_without_rpq = train_resnet50_with_rpq(trainloader, validloader, rpq=None, cache=None, num_epochs=3, device=device)\n",
    "    print(f\"Total computations without RPQ: {computations_without_rpq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242ff13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
