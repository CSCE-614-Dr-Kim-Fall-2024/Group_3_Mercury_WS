{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5c01cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Epoch 1/10\n",
      "Epoch 1/10, Loss: 0.6580\n",
      "Epoch 2/10\n",
      "Epoch 2/10, Loss: 0.5963\n",
      "Epoch 3/10\n",
      "Epoch 3/10, Loss: 0.5687\n",
      "Epoch 4/10\n",
      "Epoch 4/10, Loss: 0.5463\n",
      "Epoch 5/10\n",
      "Epoch 5/10, Loss: 0.5209\n",
      "Epoch 6/10\n",
      "Epoch 6/10, Loss: 0.5000\n",
      "Epoch 7/10\n",
      "Epoch 7/10, Loss: 0.4764\n",
      "Epoch 8/10\n",
      "Epoch 8/10, Loss: 0.4569\n",
      "Epoch 9/10\n",
      "Epoch 9/10, Loss: 0.4337\n",
      "Epoch 10/10\n",
      "Epoch 10/10, Loss: 0.4197\n",
      "Training complete!\n",
      "Cache_hits : 4591\n",
      "Cache_misses: 95409\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. Hyperparameters\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Data Preprocessing: No resizing, keep original 32x32 size\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 3. Load CIFAR-10 Dataset\n",
    "full_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#full_test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 4. Filter Dataset for Cats and Dogs\n",
    "def filter_cats_dogs(dataset):\n",
    "    targets = torch.tensor(dataset.targets)  # Convert labels to a tensor\n",
    "    mask = (targets == 3) | (targets == 5)  # Keep only labels 3 (cat) and 5 (dog)\n",
    "    dataset.targets = targets[mask].tolist()  # Update targets\n",
    "    dataset.data = dataset.data[mask.numpy()]  # Update data\n",
    "    return dataset\n",
    "\n",
    "train_dataset = filter_cats_dogs(full_train_dataset)\n",
    "#test_dataset = filter_cats_dogs(full_test_dataset)\n",
    "\n",
    "# 5. Update Labels: Map [3, 5] -> [0, 1]\n",
    "def remap_labels(dataset):\n",
    "    dataset.targets = [0 if label == 3 else 1 for label in dataset.targets]  # Cat = 0, Dog = 1\n",
    "    return dataset\n",
    "\n",
    "train_dataset = remap_labels(train_dataset)\n",
    "#test_dataset = remap_labels(test_dataset)\n",
    "\n",
    "# 6. Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# RPQ Function\n",
    "def rpq(input_vector, rows, columns):\n",
    "    #sign_quantization\n",
    "    def quantize(signature):\n",
    "        for i in range(0,columns) :\n",
    "            if signature[i] < 0:\n",
    "                signature[i] = 1\n",
    "            else:\n",
    "                signature[i] = 0\n",
    "        return signature\n",
    "\n",
    "    random_rpq_matrix = torch.randn(rows, columns, device=device)  # Move RPQ matrix to GPU\n",
    "\n",
    "    # Flatten 32 * 32 to 1 * 1024\n",
    "    flattened_vector = input_vector.view(-1)\n",
    "\n",
    "    # Dot product of input vector and R\n",
    "    signature = torch.matmul(flattened_vector, random_rpq_matrix)\n",
    "\n",
    "    # Quantization -> sign-based\n",
    "    signature_quantized = quantize(signature)\n",
    "    return signature_quantized\n",
    "\n",
    "# MCache\n",
    "mcache = {}\n",
    "cache_hits = 0\n",
    "cache_misses = 0\n",
    "binary_key = ''\n",
    "\n",
    "# 7. Define a Simple CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 classes: cat and dog\n",
    "\n",
    "    def forward(self, x):\n",
    "        global cache_hits, binary_key, cache_misses\n",
    "        if binary_key in mcache:\n",
    "            # Already first layer output is available\n",
    "            cache_hits += 1\n",
    "            x = mcache[binary_key].detach()\n",
    "        else:\n",
    "            cache_misses += 1\n",
    "            x = self.pool(torch.relu(self.conv1(x)))\n",
    "            mcache[binary_key] = x.detach()\n",
    "            \n",
    "        # Second layer is continued normally now\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)  # Move model to GPU\n",
    "\n",
    "# 8. Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 9. Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move images and labels to GPU\n",
    "\n",
    "        # Generate RPQ signature and binary key\n",
    "        rpq_signature_output = rpq(images, 1024, 20) # 1024 coz 32 * 32 (right now) , 20 columns coz signature length \n",
    "\n",
    "        # Convert the binary tensor to a string representation of binary\n",
    "        binary_key = ''.join(map(str, rpq_signature_output.tolist()))  # tensor to list and then to string\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(\"Cache_hits :\", cache_hits)\n",
    "print(\"Cache_misses:\", cache_misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126432a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7ca4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212cfb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2507f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab048d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Epoch 1/10\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 48\n",
      "First Layer->Cache_misses 9952\n",
      "Mcache Reset\n",
      "Second layer Training Complete\n",
      "Second layer->Cache_hits 45\n",
      "Second Layer->Cache_misses 9955\n",
      "Epoch 2/10\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 48\n",
      "First Layer->Cache_misses 9952\n",
      "Mcache Reset\n",
      "Second layer Training Complete\n",
      "Second layer->Cache_hits 41\n",
      "Second Layer->Cache_misses 9959\n",
      "Epoch 3/10\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 57\n",
      "First Layer->Cache_misses 9943\n",
      "Mcache Reset\n",
      "Second layer Training Complete\n",
      "Second layer->Cache_hits 64\n",
      "Second Layer->Cache_misses 9936\n",
      "Epoch 4/10\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 43\n",
      "First Layer->Cache_misses 9957\n",
      "Mcache Reset\n",
      "Second layer Training Complete\n",
      "Second layer->Cache_hits 39\n",
      "Second Layer->Cache_misses 9961\n",
      "Epoch 5/10\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 41\n",
      "First Layer->Cache_misses 9959\n",
      "Mcache Reset\n",
      "Second layer Training Complete\n",
      "Second layer->Cache_hits 62\n",
      "Second Layer->Cache_misses 9938\n",
      "Epoch 6/10\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 54\n",
      "First Layer->Cache_misses 9946\n",
      "Mcache Reset\n",
      "Second layer Training Complete\n",
      "Second layer->Cache_hits 38\n",
      "Second Layer->Cache_misses 9962\n",
      "Epoch 7/10\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 59\n",
      "First Layer->Cache_misses 9941\n",
      "Mcache Reset\n",
      "Second layer Training Complete\n",
      "Second layer->Cache_hits 45\n",
      "Second Layer->Cache_misses 9955\n",
      "Epoch 8/10\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 56\n",
      "First Layer->Cache_misses 9944\n",
      "Mcache Reset\n",
      "Second layer Training Complete\n",
      "Second layer->Cache_hits 52\n",
      "Second Layer->Cache_misses 9948\n",
      "Epoch 9/10\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 46\n",
      "First Layer->Cache_misses 9954\n",
      "Mcache Reset\n",
      "Second layer Training Complete\n",
      "Second layer->Cache_hits 49\n",
      "Second Layer->Cache_misses 9951\n",
      "Epoch 10/10\n",
      "Mcache Reset\n",
      "First Layer Training Complete\n",
      "First layer->Cache_hits 56\n",
      "First Layer->Cache_misses 9944\n",
      "Mcache Reset\n",
      "Second layer Training Complete\n",
      "Second layer->Cache_hits 46\n",
      "Second Layer->Cache_misses 9954\n",
      "Training complete!\n",
      "Cache_hits : 989\n",
      "Cache_misses: 199011\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. Hyperparameters\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Data Preprocessing: No resizing, keep original 32x32 size\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 3. Load CIFAR-10 Dataset\n",
    "full_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#full_test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 4. Filter Dataset for Cats and Dogs\n",
    "def filter_cats_dogs(dataset):\n",
    "    targets = torch.tensor(dataset.targets)  # Convert labels to a tensor\n",
    "    mask = (targets == 3) | (targets == 5)  # Keep only labels 3 (cat) and 5 (dog)\n",
    "    dataset.targets = targets[mask].tolist()  # Update targets\n",
    "    dataset.data = dataset.data[mask.numpy()]  # Update data\n",
    "    return dataset\n",
    "\n",
    "train_dataset = filter_cats_dogs(full_train_dataset)\n",
    "#test_dataset = filter_cats_dogs(full_test_dataset)\n",
    "\n",
    "# 5. Update Labels: Map [3, 5] -> [0, 1]\n",
    "def remap_labels(dataset):\n",
    "    dataset.targets = [0 if label == 3 else 1 for label in dataset.targets]  # Cat = 0, Dog = 1\n",
    "    return dataset\n",
    "\n",
    "train_dataset = remap_labels(train_dataset)\n",
    "#test_dataset = remap_labels(test_dataset)\n",
    "\n",
    "# 6. Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "outputs_final = {}\n",
    "total_cache_hits = 0\n",
    "total_cache_misses = 0\n",
    "\n",
    "# RPQ Function\n",
    "def rpq(input_vector, rows, columns):\n",
    "    #sign_quantization\n",
    "    def quantize(signature):\n",
    "        for i in range(0,columns) :\n",
    "            if signature[i] < 0:\n",
    "                signature[i] = 1\n",
    "            else:\n",
    "                signature[i] = 0\n",
    "        return signature\n",
    "\n",
    "    random_rpq_matrix = torch.randn(rows, columns, device=device)  # Move RPQ matrix to GPU\n",
    "\n",
    "    # Flatten 32 * 32 to 1 * 1024\n",
    "    flattened_vector = input_vector.view(-1)\n",
    "\n",
    "    # Dot product of input vector and R\n",
    "    signature = torch.matmul(flattened_vector, random_rpq_matrix)\n",
    "\n",
    "    # Quantization -> sign-based\n",
    "    signature_quantized = quantize(signature)\n",
    "    return signature_quantized\n",
    "\n",
    "\n",
    "def mcache_func(binary_key, mcache):\n",
    "    if binary_key in mcache:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# 7. Define a Simple CNN\n",
    "class SimpleCNN_with_RPQ_Layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN_with_RPQ_Layer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 classes: cat and dog\n",
    "        \n",
    "        self.mcache = {}\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0 \n",
    "        self.binary_key = ''\n",
    "    \n",
    "    def reset(self):\n",
    "        self.mcache = {}\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0 \n",
    "        self.binary_key = ''\n",
    "        print(\"Mcache Reset\")\n",
    "        \n",
    "    def forward(self):\n",
    "        global total_cache_hits, total_cache_misses\n",
    "        #reset mcache, cache_hits and cache_misses\n",
    "        self.reset()\n",
    "        \n",
    "        # first conv layer\n",
    "        weights_conv1 = {}\n",
    "        weights_conv2 = {}\n",
    "        input_label_GPU = {}\n",
    "        i = 0 \n",
    "        #\n",
    "        for input_image, input_label in train_loader:\n",
    "            input_image, input_label_GPU = input_image.to(device), input_label.to(device) # Move image, labels to GPU\n",
    "\n",
    "            # Generate RPQ signature and binary key\n",
    "            rpq_signature_output = rpq(input_image, 1024, 20) # 1024 coz 32 * 32 (right now) , 20 columns coz signature length \n",
    "            #print(\"Signature:\")\n",
    "            \n",
    "            # Convert the binary tensor to a string representation of binary\n",
    "            self.binary_key = ''.join(map(str, rpq_signature_output.tolist()))  # tensor to list and then to string\n",
    "            \n",
    "            if mcache_func(self.binary_key,self.mcache) == True :\n",
    "                self.cache_hits += 1\n",
    "                weights_conv1[i] = self.mcache[self.binary_key]\n",
    "            else :\n",
    "                self.cache_misses +=1\n",
    "                weights_conv1[i] = self.pool(torch.relu(self.conv1(input_image))) \n",
    "                self.mcache[self.binary_key] = weights_conv1[i]\n",
    "            i += 1\n",
    "            \n",
    "        print(\"First Layer Training Complete\")\n",
    "        total_cache_hits += self.cache_hits\n",
    "        total_cache_misses += self.cache_misses\n",
    "        print(\"First layer->Cache_hits\", self.cache_hits)\n",
    "        print(\"First Layer->Cache_misses\", self.cache_misses)\n",
    "        \n",
    "        #reset mcache, cache_hits and cache_misses\n",
    "        self.reset()\n",
    "        \n",
    "        # Second layer is continued using the output of the First conv layer (weights_conv1[]) \n",
    "        j = 0\n",
    "        for i in range(0,len(weights_conv1)):\n",
    "            # Generate RPQ signature and binary key\n",
    "            rpq_signature_output = rpq(input_image, 1024, 20) # 1024 coz 32 * 32 (right now) , 20 columns coz signature length \n",
    "\n",
    "            # Convert the binary tensor to a string representation of binary\n",
    "            self.binary_key = ''.join(map(str, rpq_signature_output.tolist()))  # tensor to list and then to string\n",
    "            \n",
    "            if mcache_func(self.binary_key,self.mcache) == True :\n",
    "                self.cache_hits += 1\n",
    "                weights_conv2[j] = self.mcache[i][self.binary_key]\n",
    "            else :\n",
    "                self.cache_misses += 1\n",
    "                weights_conv2[j] = self.pool(torch.relu(self.conv2(weights_conv1[i]))) \n",
    "                self.mcache[i][self.binary_key] = weights_conv2[i]\n",
    "            j += 1\n",
    "            \n",
    "\n",
    "        print(\"Second layer Training Complete\")            \n",
    "        total_cache_hits += self.cache_hits\n",
    "        total_cache_misses += self.cache_misses\n",
    "        print(\"Second layer->Cache_hits\", self.cache_hits)\n",
    "        print(\"Second Layer->Cache_misses\", self.cache_misses)\n",
    "        \n",
    "        #The other layers(Pool,FC1,FC2) is continued using the outputs of the Second conv layer (weights_conv2[])\n",
    "        j = 0\n",
    "        for i in range(0,len(weights_conv2)):\n",
    "            outputs_final[j] = weights_conv2[i].view(-1, 32 * 8 * 8)\n",
    "            outputs_final[j] = torch.relu(self.fc1(outputs_final[j]))\n",
    "            outputs_final[j] = self.fc2(outputs_final[j])\n",
    "            j += 1\n",
    "\n",
    "model = SimpleCNN_with_RPQ_Layer().to(device)  # Move model to GPU\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "# 8. Training Loop \n",
    "\n",
    "# Forward Propogation\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    model()\n",
    "\n",
    "#Backward Propogation\n",
    "\n",
    "        \n",
    "print(\"Training complete!\")\n",
    "print(\"Average_Cache_hits :\", total_cache_hits/10)\n",
    "print(\"Average_Cache_misses:\", total_cache_misses/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668c5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3529033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347422a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60c47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713dbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# loss calculation and Bqckward Propogation  \n",
    "    ##########################################################    \n",
    "        loss = criterion(outputs, input_label)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# 10. Test the Model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776cb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b72b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
